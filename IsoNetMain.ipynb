{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epEUpSnPgEvt","executionInfo":{"status":"ok","timestamp":1664346078230,"user_tz":-180,"elapsed":2011,"user":{"displayName":"Silas Rech","userId":"04754254435051112129"}},"outputId":"e3f3bcdc-71c9-4787-cc18-906f2a883937"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Jws-wRoFimWP","executionInfo":{"status":"ok","timestamp":1664346078232,"user_tz":-180,"elapsed":11,"user":{"displayName":"Silas Rech","userId":"04754254435051112129"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip3 install pyroomacoustics\n","!pip3 install torchmetrics\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acFneSWfgljG","outputId":"7f7267f9-19c5-4a60-880b-5c8eb4c586b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyroomacoustics\n","  Downloading pyroomacoustics-0.6.0.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 3.2 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from pyroomacoustics) (0.29.32)\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import glob\n","import random\n","import torchaudio\n","from tqdm import tqdm\n","import argparse\n"],"metadata":{"id":"mwcIxauaiTP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/')\n","#sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/dataloader.py')\n","#sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/training.py')\n","#sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/tools.py')\n","#sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/roomacoustics.py')\n","#sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/metafiles.py')\n","#sys.path.append('/content/drive/MyDrive/ColabNotebooks/IsoNet/model.py')\n","root=\"/content/drive/MyDrive/ColabNotebooks/IsoNet/\"\n"],"metadata":{"id":"5cJ35DdiquuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tools import splitStrings\n","\n","def walk_through_files(path):\n","    test = os.path.join(path, \"**\" , '*.flac')\n","    return_list = glob.glob(test, recursive=True)\n","\n","    list_possible_audio_files = []\n","    for path in return_list:\n","        minimum_file_length = 96000\n","        audiofile, sample_rate = torchaudio.load(path)\n","\n","        if len(audiofile.T) >= minimum_file_length:\n","            list_possible_audio_files.append(path)\n","\n","    #random_sample = random.choice(list_possible_audio_files)\n","\n","    return list_possible_audio_files\n","\n","\n","def generate_meta_files(root, database_length, overwrite):\n","\n","    root_dir = os.path.join(root, \"dev-clean\")\n","    root_dir_list_files = os.path.join(root, '**', '*.flac')\n","    print(root_dir)\n","\n","    speaker_files = 'AudioFiles.txt'\n","    if not os.path.exists('AudioFiles.txt') or overwrite:\n","        files = glob.glob(root_dir_list_files, recursive=True)\n","        print(\"Number of files found: {}\".format(len(files)))\n","        with open(speaker_files, 'w') as fp:\n","            for item in files:\n","                # write each item on a new line\n","                fp.write(\"%s\\n\" % item)\n","            print('List of All Audio Files Saved')\n","    else:\n","        with open(speaker_files) as f:\n","            files = f.read().splitlines()\n","\n","    with open(os.path.join(root, \"SPEAKERS.txt\")) as f:\n","        speakers = f.read().splitlines()\n","\n","    list_female = []\n","    list_male = []\n","    for speaker in speakers:\n","        if 'dev-clean' in speaker:\n","            res = splitStrings(speaker, '|')\n","            if res[1] == ' F ':\n","                list_female.append(res[0])\n","            else:\n","                list_male.append(res[0])\n","\n","    if not os.path.exists(os.path.join(root, 'PossibleFemaleSpeakers.txt')) or overwrite:\n","        all_files_female = []\n","        for m in tqdm(range(len(list_male))):\n","            possible_file_female = walk_through_files(os.path.join(root_dir, list_female[m].strip()))\n","            all_files_female = all_files_female + possible_file_female\n","\n","        with open(os.path.join(root, 'PossibleFemaleSpeakers.txt'), 'w') as fp:\n","            for item in all_files_female:\n","                # write each item on a new line\n","                fp.write(\"%s\\n\" % item)\n","            print('List of Female Speakers Saved')\n","    else:\n","        with open(os.path.join(root, 'PossibleFemaleSpeakers.txt')) as f:\n","            all_files_female = f.read().splitlines()\n","\n","    if not os.path.exists(os.path.join(root, 'PossibleMaleSpeakers.txt')) or overwrite:\n","        all_files_male = []\n","        for m in tqdm(range(len(list_male))):\n","            possible_file_male = walk_through_files(os.path.join(root_dir, list_male[m].strip()))\n","            all_files_male = all_files_male + possible_file_male\n","        with open(os.path.join(root, 'PossibleMaleSpeakers.txt'), 'w') as fp:\n","            for item in all_files_male:\n","                # write each item on a new line\n","                fp.write(\"%s\\n\" % item)\n","            print('List of Male Speakers Saved')\n","    else:\n","        with open(os.path.join(root, 'PossibleMaleSpeakers.txt')) as f:\n","            all_files_male = f.read().splitlines()\n","\n","    # Get Distribution\n","    print(\"Number of available male files: {}\".format(len(all_files_male)))\n","    print(\"Number of available female files: {}\".format(len(all_files_female)))\n","\n","    target_all = random.choices(all_files_male, k=database_length//4)\n","    interferer_all = random.choices(all_files_male, k=database_length//4)\n","\n","    target = random.choices(all_files_female, k=database_length//4)\n","    interferer = random.choices(all_files_male, k=database_length//4)\n","\n","    target_all = target_all + target\n","    interferer_all = interferer_all + interferer\n","\n","    target = random.choices(all_files_male, k=database_length//4)\n","    interferer = random.choices(all_files_female, k=database_length//4)\n","\n","    target_all = target_all + target\n","    interferer_all = interferer_all + interferer\n","\n","    target = random.choices(all_files_female, k=database_length//4)\n","    interferer = random.choices(all_files_female, k=database_length//4)\n","\n","    target_all = target_all + target\n","    interferer_all = interferer_all + interferer\n","\n","    with open(os.path.join(root, \"training_list.txt\"), 'w') as fp:\n","        for i in range(len(target_all)):\n","            # write each item on a new line\n","            fp.write(target_all[i] + ' ' + interferer_all[i] + '\\n')\n","        print('Training List Saved and Finished')\n","\n","\n","generate_meta_files(root, database_length=20000, overwrite=False)\n"],"metadata":{"id":"67S7KDyJiPal"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import glob\n","import sys\n","import random\n","import torchaudio\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","import torchmetrics\n","\n","from torch.utils.data import DataLoader\n","from training import train, model_eval\n","\n","from model import ConvTasNet\n","from dataloader import LibriSpeech\n","import argparse\n","\n","torch.backends.cudnn.benchmark = True\n","mode = \"train\"\n","model_name = 'IsoNet.pt'\n","\n","BATCH_SIZE = 16\n","\n","EPOCHS = 100\n","addnoise = False\n","fs = 16000\n","\n","total_length = 4\n","input_length = 16000 # in samples\n","win_length = int(fs*total_length)\n","\n","with open(os.path.join(root, 'training_list.txt')) as f:\n","    training_files = f.read().splitlines()\n","\n","print(mode)\n","if mode == 'train':\n","    print(\"-----------------Training Mode Started-----------------\")\n","    print(\"-----------------Building Database-----------------\")\n","\n","    train_dataset = LibriSpeech(training_files, root_dir=root, fs=fs, length=total_length, length_input=input_length, batchsize=1)\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, prefetch_factor=8, pin_memory=True)\n","\n","    print(\"-----------------Loading Model-----------------\")\n","    model = ConvTasNet()\n","    model.cuda()\n","\n","    #criterion = torchmetrics.ScaleInvariantSignalNoiseRatio(full_state_update=False).cuda()\n","\n","    criterion = torch.nn.MSELoss()\n","\n","    optim_params = model.parameters()\n","    optimizer = torch.optim.Adam(optim_params, 0.001)\n","\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True, min_lr=0)\n","    \n","    eval_dataset = LibriSpeech(training_files[:100], root_dir=root, fs=fs, length=total_length, length_input=input_length, batchsize=1)\n","    eval_loader = DataLoader(eval_dataset, batch_size=1, num_workers=2, prefetch_factor=8, pin_memory=True)\n","    print(\"-----------------Starting Training------------------\")\n","    for epoch in range(EPOCHS):\n","        \n","\n","        model = train(train_loader, model, criterion, optimizer, epoch, scheduler, loss_mode=\"sisnr\")\n","\n","        torch.save(model, model_name)\n","\n","        print(\"\\n -----------------Starting Evaluation----------------\")\n","        \n","        isolated_predictions = model_eval(eval_loader, model, fs, total_length)\n","else:\n","    print(\"-----------------Evaluation Mode Started-----------------\")\n","\n","    leaked_target, leaked_interferer, target_audio = next(iter(eval_loader))\n","\n","    target_mix = torch.reshape(torch.squeeze(leaked_target), shape=(1, int(fs*total_length)))\n","    interfering_mix = torch.reshape(torch.squeeze(leaked_interferer), shape=(1, int(fs*total_length)))\n","    target = torch.reshape(torch.squeeze(target_audio), shape=(1, int(fs*total_length)))\n","\n","    for k in range(len(target_mix)):\n","        torchaudio.save('./evaluation_sample/target_mix{}.wav'.format(k),\n","                        target_mix, 16000)\n","        torchaudio.save('./evaluation_sample/target{}.wav'.format(k),\n","                        target, 16000)\n","        torchaudio.save('./evaluation_sample/interferer_mix{}.wav'.format(k),\n","                        interfering_mix, 16000)\n","    print(\"-----------------Loading Model---------------------\")\n","    loaded_model = torch.load(model_name).cuda()\n","\n","    print(\"-----------------Loading Completed, starting evaluation...-------------\")\n","    isolated_predictions = model_eval(eval_loader, loaded_model, fs, total_length)\n","    print(\"Files Successfully Written, Finished\")\n"],"metadata":{"id":"q4bjLbTDgHqP"},"execution_count":null,"outputs":[]}]}